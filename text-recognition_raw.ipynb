{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60bc815e",
   "metadata": {},
   "source": [
    "# Model to recognise hand-written text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bca0464",
   "metadata": {},
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2b8c64",
   "metadata": {},
   "source": [
    "pip install stow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15f1a13",
   "metadata": {},
   "source": [
    "pip install mltu==0.1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe75602",
   "metadata": {},
   "source": [
    "pip install --upgrade protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "862e951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libaries\n",
    "import tensorflow as tf\n",
    "import stow\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76992789",
   "metadata": {},
   "source": [
    "# Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9ad67f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115338/115338 [00:16<00:00, 7042.14it/s] \n"
     ]
    }
   ],
   "source": [
    "dataset_path = r'C:\\Users\\ljant\\Downloads\\IAM_Words\\IAM_Words'\n",
    "\n",
    "# Initialize the dataset list and vocabulary set\n",
    "dataset = []\n",
    "vocab = set()\n",
    "max_len = 0\n",
    "\n",
    "# Path to the words.txt file\n",
    "words_file_path = os.path.join(dataset_path, \"words.txt\")\n",
    "\n",
    "# Reading lines from words.txt\n",
    "with open(words_file_path, \"r\") as file:\n",
    "    words = file.readlines()\n",
    "\n",
    "for line in tqdm(words):\n",
    "    if line.startswith(\"#\"):\n",
    "        continue\n",
    "\n",
    "    line_split = line.split(\" \")\n",
    "    if line_split[1] == \"err\":\n",
    "        continue\n",
    "\n",
    "    folder1 = line_split[0][:3]\n",
    "    folder2 = line_split[0][:8]\n",
    "    file_name = line_split[0] + \".png\"\n",
    "    label = line_split[-1].rstrip('\\n')\n",
    "\n",
    "    # Constructing the relative path to the image\n",
    "    rel_path = os.path.join(dataset_path, \"words\", folder1, folder2, file_name)\n",
    "\n",
    "    # Check if the image file exists\n",
    "    if not os.path.exists(rel_path):\n",
    "        continue\n",
    "\n",
    "    # Append the relative path and label to the dataset list\n",
    "    dataset.append([rel_path, label])\n",
    "    \n",
    "    # Update the vocabulary set with characters from the label\n",
    "    vocab.update(list(label))\n",
    "    \n",
    "    # Update the maximum label length\n",
    "    max_len = max(max_len, len(label))\n",
    "\n",
    "# Now, `dataset` is a list of [image_path, label] and `vocab` contains all unique characters in the labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "642d0cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting configs.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile configs.py\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from mltu.configs import BaseModelConfigs\n",
    "\n",
    "class ModelConfigs(BaseModelConfigs):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model_path = os.path.join(r\"C:\\Users\\ljant\\Desktop\\Ironhack\\Projects\\Final-Project-Ironhack-2024\", datetime.strftime(datetime.now(), \"%Y%m%d%H%M\"))\n",
    "        self.vocab = \"\"\n",
    "        self.height = 32\n",
    "        self.width = 128\n",
    "        self.max_text_length = 0\n",
    "        self.batch_size = 16\n",
    "        self.learning_rate = 0.0005\n",
    "        self.train_epochs = 1000\n",
    "        self.train_workers = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cddaa44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs import ModelConfigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f06b531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = ModelConfigs()\n",
    "\n",
    "configs.vocab = \"\".join(vocab)\n",
    "configs.max_text_length = max_len\n",
    "configs.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eab223f",
   "metadata": {},
   "source": [
    "# Create a data provider for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee58cda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing augmentors.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile augmentors.py\n",
    "import cv2\n",
    "import typing\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "from . import Image\n",
    "\n",
    "\"\"\" Implemented augmentors:\n",
    "- RandomBrightness\n",
    "- RandomRotate\n",
    "- RandomErodeDilate\n",
    "- RandomSharpen\n",
    "- RandomGaussianBlur\n",
    "- RandomSaltAndPepper\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def randomness_decorator(func):\n",
    "    \"\"\" Decorator for randomness \"\"\"\n",
    "    def wrapper(self, image: Image, annotation: typing.Any) -> typing.Tuple[Image, typing.Any]:\n",
    "        \"\"\" Decorator for randomness and type checking\n",
    "\n",
    "        Args:\n",
    "            image (Image): Image to be adjusted\n",
    "            annotation (typing.Any): Annotation to be adjusted\n",
    "\n",
    "        Returns:\n",
    "            image (Image): Adjusted image\n",
    "            annotation (typing.Any): Adjusted annotation\n",
    "        \"\"\"\n",
    "        # check if image is Image object\n",
    "        if not isinstance(image, Image):\n",
    "            self.logger.error(f\"image must be Image object, not {type(image)}, skipping augmentor\")\n",
    "            return image, annotation\n",
    "\n",
    "        if np.random.rand() > self._random_chance:\n",
    "            return image, annotation\n",
    "\n",
    "        # return result of function\n",
    "        return func(self, image, annotation)\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "class Augmentor:\n",
    "    \"\"\" Object that should be inherited by all augmentors\n",
    "\n",
    "    Args:\n",
    "        random_chance (float, optional): Chance of applying the augmentor. Where 0.0 is never and 1.0 is always. Defaults to 0.5.\n",
    "        log_level (int, optional): Log level for the augmentor. Defaults to logging.INFO.\n",
    "    \"\"\"\n",
    "    def __init__(self, random_chance: float=0.5, log_level: int = logging.INFO) -> None:\n",
    "        self._random_chance = random_chance\n",
    "        self._log_level = log_level\n",
    "\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "\n",
    "        assert 0 <= self._random_chance <= 1.0, \"random chance must be between 0.0 and 1.0\"\n",
    "\n",
    "    @randomness_decorator\n",
    "    def __call__(self, image: Image, annotation: typing.Any) -> typing.Tuple[Image, typing.Any]:\n",
    "        # do the augmentation here\n",
    "        return image, annotation\n",
    "\n",
    "\n",
    "class RandomBrightness(Augmentor):\n",
    "    \"\"\" Randomly adjust image brightness \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        random_chance: float = 0.5,\n",
    "        delta: int = 100,\n",
    "        log_level: int = logging.INFO,\n",
    "        ) -> None:\n",
    "        \"\"\" Randomly adjust image brightness\n",
    "\n",
    "        Args:\n",
    "            random_chance (float, optional): Chance of applying the augmentor. Where 0.0 is never and 1.0 is always. Defaults to 0.5.\n",
    "            delta (int, optional): Integer value for brightness adjustment. Defaults to 100.\n",
    "            log_level (int, optional): Log level for the augmentor. Defaults to logging.INFO.\n",
    "        \"\"\"\n",
    "        super(RandomBrightness, self).__init__(random_chance, log_level)\n",
    "\n",
    "        assert 0 <= delta <= 255.0, \"Delta must be between 0.0 and 255.0\"\n",
    "\n",
    "        self._delta = delta\n",
    "\n",
    "    @randomness_decorator\n",
    "    def __call__(self, image: Image, annotation: typing.Any) -> typing.Tuple[Image, typing.Any]:\n",
    "        \"\"\" Randomly adjust image brightness\n",
    "\n",
    "        Args:\n",
    "            image (Image): Image to be adjusted\n",
    "            annotation (typing.Any): Annotation to be adjusted\n",
    "\n",
    "        Returns:\n",
    "            image (Image): Adjusted image\n",
    "            annotation (typing.Any): Adjusted annotation if necessary\n",
    "        \"\"\"\n",
    "        value = 1 + np.random.uniform(-self._delta, self._delta) / 255\n",
    "\n",
    "        hsv = np.array(image.HSV(), dtype = np.float32)\n",
    "\n",
    "        hsv[:, :, 1] = hsv[:, :, 1] * value\n",
    "        hsv[:, :, 2] = hsv[:, :, 2] * value\n",
    "\n",
    "        hsv = np.uint8(np.clip(hsv, 0, 255))\n",
    "\n",
    "        img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "        image.update(img)\n",
    "\n",
    "        return image, annotation\n",
    "\n",
    "\n",
    "class RandomRotate(Augmentor):\n",
    "    \"\"\" Randomly rotate image\"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        random_chance: float = 0.5,\n",
    "        angle: typing.Union[int, typing.List]=30, \n",
    "        borderValue: typing.Tuple[int, int, int]=None,\n",
    "        log_level: int = logging.INFO,\n",
    "        ) -> None:\n",
    "        \"\"\" Randomly rotate image \n",
    "\n",
    "        Args:\n",
    "            random_chance (float): Float between 0.0 and 1.0 setting bounds for random probability. Defaults to 0.5.\n",
    "            angle (int, list): Integer value or list of integer values for image rotation\n",
    "            borderValue (tuple): Tuple of 3 integers, setting border color for image rotation\n",
    "            log_level (int): Log level for the augmentor. Defaults to logging.INFO.\n",
    "        \"\"\"\n",
    "        super(RandomRotate, self).__init__(random_chance, log_level)\n",
    "\n",
    "        self._angle = angle\n",
    "        self._borderValue = borderValue\n",
    "\n",
    "    @randomness_decorator\n",
    "    def __call__(self, image: Image, annotation: typing.Any) -> typing.Tuple[Image, typing.Any]:\n",
    "        \"\"\" Randomly rotate image\n",
    "\n",
    "        Args:\n",
    "            image (Image): Image to be adjusted\n",
    "            annotation (typing.Any): Annotation to be adjusted\n",
    "\n",
    "        Returns:\n",
    "            image (Image): Adjusted image\n",
    "            annotation (typing.Any): Adjusted annotation\n",
    "        \"\"\"\n",
    "        # check if angle is list of angles or signle angle value\n",
    "        if isinstance(self._angle, list):\n",
    "            angle = float(np.random.choice(self._angle))\n",
    "        else:\n",
    "            angle = float(np.random.uniform(-self._angle, self._angle))\n",
    "\n",
    "        # generate random border color\n",
    "        borderValue = np.random.randint(0, 255, 3) if self._borderValue is None else self._borderValue\n",
    "        borderValue = [int(v) for v in borderValue]\n",
    "\n",
    "        # grab the dimensions of the image and then determine the centre\n",
    "        center_x, center_y = image.center\n",
    "\n",
    "        # grab the rotation matrix (applying the negative of the\n",
    "        # angle to rotate clockwise), then grab the sine and cosine\n",
    "        # (i.e., the rotation components of the matrix)\n",
    "        M = cv2.getRotationMatrix2D((center_x, center_y), angle, 1.0)\n",
    "        cos = np.abs(M[0, 0])\n",
    "        sin = np.abs(M[0, 1])\n",
    "\n",
    "        # compute the new bounding dimensions of the image\n",
    "        nW = int((image.height * sin) + (image.width * cos))\n",
    "        nH = int((image.height * cos) + (image.width * sin))\n",
    "\n",
    "        # adjust the rotation matrix to take into account translation\n",
    "        M[0, 2] += (nW / 2) - center_x\n",
    "        M[1, 2] += (nH / 2) - center_y\n",
    "\n",
    "        # perform the actual rotation and return the image\n",
    "        img = cv2.warpAffine(image.numpy(), M, (nW, nH), borderValue=borderValue)\n",
    "        image.update(img)\n",
    "\n",
    "        return image, annotation\n",
    "\n",
    "\n",
    "class RandomErodeDilate(Augmentor):\n",
    "    \"\"\" Randomly erode and dilate image\"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        random_chance: float = 0.5,\n",
    "        kernel_size: typing.Tuple[int, int]=(1, 1), \n",
    "        log_level: int = logging.INFO,\n",
    "        ) -> None:\n",
    "        \"\"\" Randomly erode and dilate image\n",
    "        \n",
    "        Args:\n",
    "            random_chance (float): Float between 0.0 and 1.0 setting bounds for random probability. Defaults to 0.5.\n",
    "            kernel_size (tuple): Tuple of 2 integers, setting kernel size for erosion and dilation\n",
    "            log_level (int): Log level for the augmentor. Defaults to logging.INFO.\n",
    "        \"\"\"\n",
    "        super(RandomErodeDilate, self).__init__(random_chance, log_level)\n",
    "        self._kernel_size = kernel_size\n",
    "\n",
    "    @randomness_decorator\n",
    "    def __call__(self, image: Image, annotation: typing.Any) -> typing.Tuple[Image, typing.Any]:\n",
    "        \"\"\" Randomly erode and dilate image\n",
    "\n",
    "        Args:\n",
    "            image (Image): Image to be eroded and dilated\n",
    "            annotation (typing.Any): Annotation to be adjusted\n",
    "\n",
    "        Returns:\n",
    "            image (Image): Eroded and dilated image\n",
    "            annotation (typing.Any): Adjusted annotation if necessary\n",
    "        \"\"\"\n",
    "        kernel = np.ones(self._kernel_size, np.uint8)\n",
    "\n",
    "        if np.random.rand() <= 0.5:\n",
    "            img = cv2.erode(image.numpy(), kernel, iterations=1)\n",
    "        else:\n",
    "            img = cv2.dilate(image.numpy(), kernel, iterations=1)\n",
    "\n",
    "        image.update(img)\n",
    "\n",
    "        return image, annotation\n",
    "\n",
    "\n",
    "class RandomSharpen(Augmentor):\n",
    "    \"\"\" Randomly sharpen image\"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        random_chance: float = 0.5,\n",
    "        alpha: float = 0.25,\n",
    "        lightness_range: typing.Tuple = (0.75, 2.0),\n",
    "        kernel: np.ndarray = None,\n",
    "        kernel_anchor: np.ndarray = None,\n",
    "        log_level: int = logging.INFO,\n",
    "        ) -> None:\n",
    "        \"\"\" Randomly sharpen image\n",
    "        \n",
    "        Args:\n",
    "            random_chance (float): Float between 0.0 and 1.0 setting bounds for random probability. Defaults to 0.5.\n",
    "            alpha (float): Float between 0.0 and 1.0 setting bounds for random probability\n",
    "            lightness_range (tuple): Tuple of 2 floats, setting bounds for random lightness change\n",
    "            kernel (np.ndarray): Numpy array of kernel for image convolution\n",
    "            kernel_anchor (np.ndarray): Numpy array of kernel anchor for image convolution\n",
    "            log_level (int): Log level for the augmentor. Defaults to logging.INFO.\n",
    "        \"\"\"\n",
    "        super(RandomSharpen, self).__init__(random_chance, log_level)\n",
    "\n",
    "        self._alpha_range = (alpha, 1.0)\n",
    "        self._ligtness_range = lightness_range\n",
    "        self._lightness_anchor = 8\n",
    "\n",
    "        self._kernel = np.array([[-1, -1, -1], [-1,  1, -1], [-1, -1, -1]], dtype=np.float32) if kernel is None else kernel\n",
    "        self._kernel_anchor = np.array([[0, 0, 0], [0, 1, 0], [0, 0, 0]], dtype=np.float32) if kernel_anchor is None else kernel_anchor\n",
    "\n",
    "        assert 0 <= alpha <= 1.0, \"Alpha must be between 0.0 and 1.0\"\n",
    "\n",
    "    @randomness_decorator\n",
    "    def __call__(self, image: Image, annotation: typing.Any) -> typing.Tuple[Image, typing.Any]:\n",
    "        \"\"\" Randomly sharpen image\n",
    "\n",
    "        Args:\n",
    "            image (Image): Image to be sharpened\n",
    "            annotation (typing.Any): Annotation to be adjusted\n",
    "\n",
    "        Returns:\n",
    "            image (Image): Sharpened image\n",
    "            annotation (typing.Any): Adjusted annotation if necessary\n",
    "        \"\"\"\n",
    "        lightness = np.random.uniform(*self._ligtness_range)\n",
    "        alpha = np.random.uniform(*self._alpha_range)\n",
    "\n",
    "        kernel = self._kernel_anchor  * (self._lightness_anchor + lightness) + self._kernel\n",
    "        kernel -= self._kernel_anchor\n",
    "        kernel = (1 - alpha) * self._kernel_anchor + alpha * kernel\n",
    "\n",
    "        # Apply sharpening to each channel\n",
    "        r, g, b = cv2.split(image.numpy())\n",
    "        r_sharp = cv2.filter2D(r, -1, kernel)\n",
    "        g_sharp = cv2.filter2D(g, -1, kernel)\n",
    "        b_sharp = cv2.filter2D(b, -1, kernel)\n",
    "\n",
    "        # Merge the sharpened channels back into the original image\n",
    "        image.update(cv2.merge([r_sharp, g_sharp, b_sharp]))\n",
    "\n",
    "        return image, annotation\n",
    "    \n",
    "\n",
    "class RandomGaussianBlur(Augmentor):\n",
    "    \"\"\" Randomly erode and dilate image\"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        random_chance: float = 0.5,\n",
    "        log_level: int = logging.INFO,\n",
    "        sigma: typing.Union[int, float] = 0.5,\n",
    "        ) -> None:\n",
    "        \"\"\" Randomly erode and dilate image\n",
    "        \n",
    "        Args:\n",
    "            random_chance (float): Float between 0.0 and 1.0 setting bounds for random probability. Defaults to 0.5.\n",
    "            log_level (int): Log level for the augmentor. Defaults to logging.INFO.\n",
    "            sigma (int, float): standard deviation of the Gaussian kernel\n",
    "        \"\"\"\n",
    "        super(RandomGaussianBlur, self).__init__(random_chance, log_level)\n",
    "        self.sigma = sigma\n",
    "\n",
    "    @randomness_decorator\n",
    "    def __call__(self, image: Image, annotation: typing.Any) -> typing.Tuple[Image, typing.Any]:\n",
    "        \"\"\" Randomly blurs an image with a Gaussian filter\n",
    "\n",
    "        Args:\n",
    "            image (Image): Image to be blurred\n",
    "            annotation (typing.Any): Annotation to be blurred\n",
    "\n",
    "        Returns:\n",
    "            image (Image): Blurred image\n",
    "            annotation (typing.Any): Blurred annotation if necessary\n",
    "        \"\"\"\n",
    "        img = cv2.GaussianBlur(image.numpy(), (0, 0), self.sigma)\n",
    "\n",
    "        image.update(img)\n",
    "\n",
    "        return image, annotation\n",
    "    \n",
    "\n",
    "class RandomSaltAndPepper(Augmentor):\n",
    "    \"\"\" Randomly add Salt and Pepper noise to image\"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        random_chance: float = 0.5,\n",
    "        log_level: int = logging.INFO,\n",
    "        salt_vs_pepper: float = 0.5,\n",
    "        amount: float = 0.1,\n",
    "        ) -> None:\n",
    "        \"\"\" Randomly add Salt and Pepper noise to image\n",
    "        \n",
    "        Args:\n",
    "            random_chance (float): Float between 0.0 and 1.0 setting bounds for random probability. Defaults to 0.5.\n",
    "            log_level (int): Log level for the augmentor. Defaults to logging.INFO.\n",
    "            salt_vs_pepper (float): ratio of salt vs pepper. Defaults to 0.5.\n",
    "            amount (float): proportion of the image to be salted and peppered. Defaults to 0.1.\n",
    "        \"\"\"\n",
    "        super(RandomSaltAndPepper, self).__init__(random_chance, log_level)\n",
    "        self.salt_vs_pepper = salt_vs_pepper\n",
    "        self.amount = amount\n",
    "        \n",
    "        assert 0 <= salt_vs_pepper <= 1.0, \"salt_vs_pepper must be between 0.0 and 1.0\"\n",
    "        assert 0 <= amount <= 1.0, \"amount must be between 0.0 and 1.0\"\n",
    "\n",
    "    @randomness_decorator\n",
    "    def __call__(self, image: Image, annotation: typing.Any) -> typing.Tuple[Image, typing.Any]:\n",
    "        \"\"\" Randomly add salt and pepper noise to an image\n",
    "\n",
    "        Args:\n",
    "            image (Image): Image to be noised\n",
    "            annotation (typing.Any): Annotation to be noised\n",
    "\n",
    "        Returns:\n",
    "            image (Image): Noised image\n",
    "            annotation (typing.Any): Noised annotation if necessary\n",
    "        \"\"\"\n",
    "        img = image.numpy()\n",
    "        height, width, channels = img.shape\n",
    "\n",
    "        # Salt mode\n",
    "        num_salt = int(self.amount * height * width * self.salt_vs_pepper)\n",
    "        row_coords = np.random.randint(0, height, size=num_salt)\n",
    "        col_coords = np.random.randint(0, width, size=num_salt)\n",
    "        img[row_coords, col_coords, :] = [255, 255, channels]\n",
    "\n",
    "        # Pepper mode\n",
    "        num_pepper = int(self.amount * height * width * (1.0 - self.salt_vs_pepper))\n",
    "        row_coords = np.random.randint(0, height, size=num_pepper)\n",
    "        col_coords = np.random.randint(0, width, size=num_pepper)\n",
    "        img[row_coords, col_coords, :] = [0, 0, channels]\n",
    "\n",
    "        image.update(img)\n",
    "\n",
    "        return image, annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a00b075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dataProvider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dataProvider.py\n",
    "import os\n",
    "import copy\n",
    "import typing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from augmentors import Augmentor\n",
    "from transformers import Transformer\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format=\"%(asctime)s %(levelname)s %(name)s: %(message)s\")\n",
    "\n",
    "\n",
    "class DataProvider:\n",
    "    def __init__(\n",
    "            self,\n",
    "            dataset: typing.Union[str, list, pd.DataFrame],\n",
    "            data_preprocessors: typing.List[typing.Callable] = None,\n",
    "            batch_size: int = 4,\n",
    "            shuffle: bool = True,\n",
    "            initial_epoch: int = 1,\n",
    "            augmentors: typing.List[Augmentor] = None,\n",
    "            transformers: typing.List[Transformer] = None,\n",
    "            skip_validation: bool = True,\n",
    "            limit: int = None,\n",
    "            use_cache: bool = False,\n",
    "            log_level: int = logging.INFO,\n",
    "    ) -> None:\n",
    "        \"\"\" Standardised object for providing data to a model while training.\n",
    "\n",
    "        Attributes:\n",
    "            dataset (str, list, pd.DataFrame): Path to dataset, list of data or pandas dataframe of data.\n",
    "            data_preprocessors (list): List of data preprocessors. (e.g. [read image, read audio, etc.])\n",
    "            batch_size (int): The number of samples to include in each batch. Defaults to 4.\n",
    "            shuffle (bool): Whether to shuffle the data. Defaults to True.\n",
    "            initial_epoch (int): The initial epoch. Defaults to 1.\n",
    "            augmentors (list, optional): List of augmentor functions. Defaults to None.\n",
    "            transformers (list, optional): List of transformer functions. Defaults to None.\n",
    "            skip_validation (bool, optional): Whether to skip validation. Defaults to True.\n",
    "            limit (int, optional): Limit the number of samples in the dataset. Defaults to None.\n",
    "            use_cache (bool, optional): Whether to cache the dataset. Defaults to False.\n",
    "            log_level (int, optional): The log level. Defaults to logging.INFO.\n",
    "        \"\"\"\n",
    "        self._dataset = dataset\n",
    "        self._data_preprocessors = [] if data_preprocessors is None else data_preprocessors\n",
    "        self._batch_size = batch_size\n",
    "        self._shuffle = shuffle\n",
    "        self._epoch = initial_epoch\n",
    "        self._augmentors = [] if augmentors is None else augmentors\n",
    "        self._transformers = [] if transformers is None else transformers\n",
    "        self._skip_validation = skip_validation\n",
    "        self._limit = limit\n",
    "        self._use_cache = use_cache\n",
    "        self._step = 0\n",
    "        self._cache = {}\n",
    "        self._on_epoch_end_remove = []\n",
    "\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.logger.setLevel(log_level)\n",
    "\n",
    "        # Validate dataset\n",
    "        if not skip_validation:\n",
    "            self._dataset = self.validate(dataset)\n",
    "        else:\n",
    "            self.logger.info(\"Skipping Dataset validation...\")\n",
    "\n",
    "        if limit:\n",
    "            self.logger.info(f\"Limiting dataset to {limit} samples.\")\n",
    "            self._dataset = self._dataset[:limit]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Denotes the number of batches per epoch \"\"\"\n",
    "        return int(np.ceil(len(self._dataset) / self._batch_size))\n",
    "\n",
    "    @property\n",
    "    def augmentors(self) -> typing.List[Augmentor]:\n",
    "        \"\"\" Return augmentors \"\"\"\n",
    "        return self._augmentors\n",
    "\n",
    "    @augmentors.setter\n",
    "    def augmentors(self, augmentors: typing.List[Augmentor]):\n",
    "        \"\"\" Decorator for adding augmentors to the DataProvider \"\"\"\n",
    "        for augmentor in augmentors:\n",
    "            if isinstance(augmentor, Augmentor):\n",
    "                if self._augmentors is not None:\n",
    "                    self._augmentors.append(augmentor)\n",
    "                else:\n",
    "                    self._augmentors = [augmentor]\n",
    "\n",
    "            else:\n",
    "                self.logger.warning(f\"Augmentor {augmentor} is not an instance of Augmentor.\")\n",
    "\n",
    "    @property\n",
    "    def transformers(self) -> typing.List[Transformer]:\n",
    "        \"\"\" Return transformers \"\"\"\n",
    "        return self._transformers\n",
    "\n",
    "    @transformers.setter\n",
    "    def transformers(self, transformers: typing.List[Transformer]):\n",
    "        \"\"\" Decorator for adding transformers to the DataProvider \"\"\"\n",
    "        for transformer in transformers:\n",
    "            if isinstance(transformer, Transformer):\n",
    "                if self._transformers is not None:\n",
    "                    self._transformers.append(transformer)\n",
    "                else:\n",
    "                    self._transformers = [transformer]\n",
    "\n",
    "            else:\n",
    "                self.logger.warning(f\"Transformer {transformer} is not an instance of Transformer.\")\n",
    "\n",
    "    @property\n",
    "    def epoch(self) -> int:\n",
    "        \"\"\" Return Current Epoch\"\"\"\n",
    "        return self._epoch\n",
    "\n",
    "    @property\n",
    "    def step(self) -> int:\n",
    "        \"\"\" Return Current Step\"\"\"\n",
    "        return self._step\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\" Shuffle training dataset and increment epoch counter at the end of each epoch. \"\"\"\n",
    "        self._epoch += 1\n",
    "        if self._shuffle:\n",
    "            np.random.shuffle(self._dataset)\n",
    "\n",
    "        # Remove any samples that were marked for removal\n",
    "        for remove in self._on_epoch_end_remove:\n",
    "            self.logger.warning(f\"Removing {remove} from dataset.\")\n",
    "            self._dataset.remove(remove)\n",
    "        self._on_epoch_end_remove = []\n",
    "\n",
    "    def validate_list_dataset(self, dataset: list) -> list:\n",
    "        \"\"\" Validate a list dataset \"\"\"\n",
    "        validated_data = [data for data in tqdm(dataset, desc=\"Validating Dataset\") if os.path.exists(data[0])]\n",
    "        if not validated_data:\n",
    "            raise FileNotFoundError(\"No valid data found in dataset.\")\n",
    "\n",
    "        return validated_data\n",
    "\n",
    "    def validate(self, dataset: typing.Union[str, list, pd.DataFrame]) -> typing.Union[list, str]:\n",
    "        \"\"\" Validate the dataset and return the dataset \"\"\"\n",
    "\n",
    "        if isinstance(dataset, str):\n",
    "            if os.path.exists(dataset):\n",
    "                return dataset\n",
    "        elif isinstance(dataset, list):\n",
    "            return self.validate_list_dataset(dataset)\n",
    "        elif isinstance(dataset, pd.DataFrame):\n",
    "            return self.validate_list_dataset(dataset.values.tolist())\n",
    "        else:\n",
    "            raise TypeError(\"Dataset must be a path, list or pandas dataframe.\")\n",
    "\n",
    "    def split(self, split: float = 0.9, shuffle: bool = True) -> typing.Tuple[typing.Any, typing.Any]:\n",
    "        \"\"\" Split current data provider into training and validation data providers. \n",
    "        \n",
    "        Args:\n",
    "            split (float, optional): The split ratio. Defaults to 0.9.\n",
    "            shuffle (bool, optional): Whether to shuffle the dataset. Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            train_data_provider (tf.keras.utils.Sequence): The training data provider.\n",
    "            val_data_provider (tf.keras.utils.Sequence): The validation data provider.\n",
    "        \"\"\"\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self._dataset)\n",
    "            \n",
    "        train_data_provider, val_data_provider = copy.deepcopy(self), copy.deepcopy(self)\n",
    "        train_data_provider._dataset = self._dataset[:int(len(self._dataset) * split)]\n",
    "        val_data_provider._dataset = self._dataset[int(len(self._dataset) * split):]\n",
    "\n",
    "        return train_data_provider, val_data_provider\n",
    "\n",
    "    def to_csv(self, path: str, index: bool = False) -> None:\n",
    "        \"\"\" Save the dataset to a csv file \n",
    "\n",
    "        Args:\n",
    "            path (str): The path to save the csv file.\n",
    "            index (bool, optional): Whether to save the index. Defaults to False.\n",
    "        \"\"\"\n",
    "        df = pd.DataFrame(self._dataset)\n",
    "        df.to_csv(path, index=index)\n",
    "\n",
    "    def get_batch_annotations(self, index: int) -> typing.List:\n",
    "        \"\"\" Returns a batch of annotations by batch index in the dataset\n",
    "\n",
    "        Args:\n",
    "            index (int): The index of the batch in \n",
    "\n",
    "        Returns:\n",
    "            batch_annotations (list): A list of batch annotations\n",
    "        \"\"\"\n",
    "        self._step = index\n",
    "        start_index = index * self._batch_size\n",
    "\n",
    "        # Get batch indexes\n",
    "        batch_indexes = [i for i in range(start_index, start_index + self._batch_size) if i < len(self._dataset)]\n",
    "\n",
    "        # Read batch data\n",
    "        batch_annotations = [self._dataset[index] for index in batch_indexes]\n",
    "\n",
    "        return batch_annotations\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \"\"\" Create a generator that iterate over the Sequence.\"\"\"\n",
    "        for item in (self[i] for i in range(len(self))):\n",
    "            yield item\n",
    "\n",
    "    def process_data(self, batch_data):\n",
    "        \"\"\" Process data batch of data \"\"\"\n",
    "        if self._use_cache and batch_data[0] in self._cache:\n",
    "            data, annotation = copy.deepcopy(self._cache[batch_data[0]])\n",
    "        else:\n",
    "            data, annotation = batch_data\n",
    "            for preprocessor in self._data_preprocessors:\n",
    "                data, annotation = preprocessor(data, annotation)\n",
    "            \n",
    "            if data is None or annotation is None:\n",
    "                self.logger.warning(\"Data or annotation is None, marking for removal on epoch end.\")\n",
    "                self._on_epoch_end_remove.append(batch_data)\n",
    "                return None, None\n",
    "            \n",
    "            if self._use_cache and batch_data[0] not in self._cache:\n",
    "                self._cache[batch_data[0]] = (copy.deepcopy(data), copy.deepcopy(annotation))\n",
    "\n",
    "        # Then augment, transform and postprocess the batch data\n",
    "        for objects in [self._augmentors, self._transformers]:\n",
    "            for _object in objects:\n",
    "                data, annotation = _object(data, annotation)\n",
    "\n",
    "        # Convert to numpy array if not already\n",
    "        if not isinstance(data, np.ndarray):\n",
    "            data = data.numpy()\n",
    "\n",
    "        # Convert to numpy array if not already\n",
    "        # TODO: This is a hack, need to fix this\n",
    "        if not isinstance(annotation, (np.ndarray, int, float, str, np.uint8, float)):\n",
    "            annotation = annotation.numpy()\n",
    "\n",
    "        return data, annotation\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        \"\"\" Returns a batch of data by batch index\"\"\"\n",
    "        dataset_batch = self.get_batch_annotations(index)\n",
    "        \n",
    "        # First read and preprocess the batch data\n",
    "        batch_data, batch_annotations = [], []\n",
    "        for index, batch in enumerate(dataset_batch):\n",
    "\n",
    "            data, annotation = self.process_data(batch)\n",
    "\n",
    "            if data is None or annotation is None:\n",
    "                self.logger.warning(\"Data or annotation is None, skipping.\")\n",
    "                continue\n",
    "\n",
    "            batch_data.append(data)\n",
    "            batch_annotations.append(annotation)\n",
    "\n",
    "        return np.array(batch_data), np.array(batch_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c734340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\ljant\\\\Desktop\\\\Ironhack\\\\Projects\\\\Final-Project-Ironhack-2024', 'C:\\\\Users\\\\ljant\\\\anaconda3\\\\python39.zip', 'C:\\\\Users\\\\ljant\\\\anaconda3\\\\DLLs', 'C:\\\\Users\\\\ljant\\\\anaconda3\\\\lib', 'C:\\\\Users\\\\ljant\\\\anaconda3', '', 'C:\\\\Users\\\\ljant\\\\anaconda3\\\\lib\\\\site-packages', 'C:\\\\Users\\\\ljant\\\\anaconda3\\\\lib\\\\site-packages\\\\locket-0.2.1-py3.9.egg', 'C:\\\\Users\\\\ljant\\\\anaconda3\\\\lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\ljant\\\\anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\ljant\\\\anaconda3\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\ljant\\\\anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\ljant\\\\.ipython', 'C:\\\\Users\\\\ljant\\\\Desktop\\\\Ironhack\\\\Projects\\\\Final-Project-Ironhack-2024\\\\dataProvider.py']\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4748/359171196.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Try importing again\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0maugmentors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAugmentor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Ironhack\\Projects\\Final-Project-Ironhack-2024\\augmentors.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \"\"\" Implemented augmentors:\n",
      "\u001b[1;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Print the current search path\n",
    "print(sys.path)\n",
    "\n",
    "# Replace '/path/to/your/module' with the actual path to the directory containing your modules\n",
    "module_path = r'C:\\Users\\ljant\\Desktop\\Ironhack\\Projects\\Final-Project-Ironhack-2024\\dataProvider.py'\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Try importing again\n",
    "from augmentors import Augmentor\n",
    "from transformers import Transformer\n",
    "\n",
    "data_provider = DataProvider(\n",
    "    dataset=dataset,\n",
    "    skip_validation=True,\n",
    "    batch_size=configs.batch_size,\n",
    "    data_preprocessors=[ImageReader(CVImage)],\n",
    "    transformers=[\n",
    "        ImageResizer(configs.width, configs.height, keep_aspect_ratio=False),\n",
    "        LabelIndexer(configs.vocab),\n",
    "        LabelPadding(max_word_length=configs.max_text_length, padding_value=len(configs.vocab)),\n",
    "        ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b75078f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataProvider' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4748/1708003216.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m data_provider = DataProvider(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mskip_validation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdata_preprocessors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mImageReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCVImage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DataProvider' is not defined"
     ]
    }
   ],
   "source": [
    "data_provider = DataProvider(\n",
    "    dataset=dataset,\n",
    "    skip_validation=True,\n",
    "    batch_size=configs.batch_size,\n",
    "    data_preprocessors=[ImageReader(CVImage)],\n",
    "    transformers=[\n",
    "        ImageResizer(configs.width, configs.height, keep_aspect_ratio=False),\n",
    "        LabelIndexer(configs.vocab),\n",
    "        LabelPadding(max_word_length=configs.max_text_length, padding_value=len(configs.vocab)),\n",
    "        ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5394b389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b91387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92aeeeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "\n",
    "from mltu.tensorflow.model_utils import residual_block\n",
    "\n",
    "\n",
    "def train_model(input_dim, output_dim, activation=\"leaky_relu\", dropout=0.2):\n",
    "    \n",
    "    inputs = layers.Input(shape=input_dim, name=\"input\")\n",
    "\n",
    "    # normalize images here instead in preprocessing step\n",
    "    input = layers.Lambda(lambda x: x / 255)(inputs)\n",
    "\n",
    "    x1 = residual_block(input, 16, activation=activation, skip_conv=True, strides=1, dropout=dropout)\n",
    "\n",
    "    x2 = residual_block(x1, 16, activation=activation, skip_conv=True, strides=2, dropout=dropout)\n",
    "    x3 = residual_block(x2, 16, activation=activation, skip_conv=False, strides=1, dropout=dropout)\n",
    "\n",
    "    x4 = residual_block(x3, 32, activation=activation, skip_conv=True, strides=2, dropout=dropout)\n",
    "    x5 = residual_block(x4, 32, activation=activation, skip_conv=False, strides=1, dropout=dropout)\n",
    "\n",
    "    x6 = residual_block(x5, 64, activation=activation, skip_conv=True, strides=2, dropout=dropout)\n",
    "    x7 = residual_block(x6, 64, activation=activation, skip_conv=True, strides=1, dropout=dropout)\n",
    "\n",
    "    x8 = residual_block(x7, 64, activation=activation, skip_conv=False, strides=1, dropout=dropout)\n",
    "    x9 = residual_block(x8, 64, activation=activation, skip_conv=False, strides=1, dropout=dropout)\n",
    "\n",
    "    squeezed = layers.Reshape((x9.shape[-3] * x9.shape[-2], x9.shape[-1]))(x9)\n",
    "\n",
    "    blstm = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(squeezed)\n",
    "    blstm = layers.Dropout(dropout)(blstm)\n",
    "\n",
    "    output = layers.Dense(output_dim + 1, activation=\"softmax\", name=\"output\")(blstm)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91e43ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5601f0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
